"""
Predict.py

2025/02/14
è‚¡åƒ¹é æ¸¬æ¨¡å‹ç”¨æ•¸æ“šè™•ç†æ¨¡çµ„
1. ä½¿ç”¨éå»5å¤©rolling.meanä½œç‚ºXçš„ç”Ÿæˆæ–¹å¼ï¼Œä¾ç…§è®Šæ•¸ç‰¹æ€§é¸æ“‡æ˜¯å¦rolling
2. ä½¿ç”¨æœªä¾†ä¸€é€±çš„å ±é…¬ä½œç‚ºy
3. å°šæœªåŠ å…¥è¡Œæ¥­
4. åªä¿ç•™æ¯é€±ä¸‰çš„æ•¸æ“šé€²è¡Œé æ¸¬ 

"""
import pandas as pd
import numpy as np
import warnings
import importlib
from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_squared_error, log_loss, accuracy_score
import xgboost as xgb
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from collections import defaultdict

from sklearn.decomposition import PCA

class MarketNeutralDataProcessor:

    def __init__(self, data, config, industry_dict):
        """
        åˆå§‹åŒ–æ•¸æ“šè™•ç†å™¨
        :param data: DataFrame, åŒ…å«æ‰€æœ‰æ—¥è³‡æ–™
        :param config: dict, è®Šæ•¸åç¨±çš„è¨­å®šï¼Œä¾‹å¦‚ï¼š
            {
                'date': 'date',
                'stock_id': 'stock_id',
                'stock_name': 'stock_name',
                'price': 'close',
                'volume': 'volume',
                'no_rolling': ['P/E', 'P/B', 'ROE', 'div_yield'],
                'rolling': ['60vol', '5vol']
            }
        :param industry_dict: dict, è‚¡ç¥¨åç¨±å°æ‡‰çš„è¡Œæ¥­åˆ†é¡ï¼Œä¾‹å¦‚ï¼š
            {'å°ç©é›»': 'åŠå°é«”', 'é´»æµ·': 'é›»å­', 'çµ±ä¸€': 'é£Ÿå“', ...}
        """
        self.data = data.copy()  # é˜²æ­¢ä¿®æ”¹åŸå§‹æ•¸æ“š
        self.config = config
        self.industry_dict = industry_dict

    def remove_incomplete_days(self):

        """ ç§»é™¤ç•¶å¤©è‚¡ç¥¨æ•¸é‡å°æ–¼ 50 æª”çš„è³‡æ–™ """
        self.data[self.config['date']] = pd.to_datetime(self.data[self.config['date']])  # ç¢ºä¿æ—¥æœŸæ ¼å¼
        daily_stock_count = self.data.groupby(self.config['date'])[self.config['stock_id']].nunique()
        valid_dates = daily_stock_count[daily_stock_count >= 50].index
        self.data = self.data[self.data[self.config['date']].isin(valid_dates)]
        return self.data

    def convert_to_numeric(self):
        """ ç¢ºä¿æ‰€æœ‰è®Šæ•¸ç‚ºæ•¸å€¼å‹ï¼Œé˜²æ­¢ object å‹æ•¸æ“šå½±éŸ¿æ©Ÿå™¨å­¸ç¿’ """
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", category=FutureWarning)  # å±è”½ FutureWarning
            
            for col in self.data.columns:
                if col not in [self.config['date'], self.config['stock_id'], self.config['stock_name']] :  # æ’é™¤éæ•¸å€¼å‹è®Šæ•¸
                    self.data[col] = pd.to_numeric(self.data[col], errors='coerce')  # ç„¡æ³•è½‰æ›çš„å€¼è½‰ NaN
            
            self.data.fillna(0, inplace=True)  # å¡«è£œ NaN
            self.data.infer_objects(copy=False)  # é¿å… FutureWarning
            self.data = self.data.copy()
        
        return self.data

    def calculate_weekly_return(self):

        """ è¨ˆç®—é€±å ±é…¬ (å¾Œ5å€‹äº¤æ˜“æ—¥çš„å ±é…¬) ä½œç‚º Y """
        self.data = self.data.sort_values([self.config['stock_id'],
                                           self.config['date']])
        self.data['future_price'] = self.data.groupby(self.config['stock_id'])[self.config['price']].shift(-5)
        self.data.loc[:, 'weekly_return'] = (self.data['future_price'] - self.data[self.config['price']]) / self.data[self.config['price']]
        self.data.loc[:, 'weekly_return_c'] = (self.data['weekly_return'] > 0).astype(int)
        self.data = self.data.copy()

        self.data['prev_price'] = self.data.groupby(self.config['stock_id'])[self.config['price']].shift(5)
        self.data.loc[:, 'prev_weekly_return'] = (self.data[self.config['price']] - self.data['prev_price']) / self.data['prev_price']

        self.data = self.data.copy()

        return self.data
    
    def calculate_weekly_return_wrong(self):

        """ è¨ˆç®—é€±å ±é…¬ (å¾Œ5å€‹äº¤æ˜“æ—¥çš„å ±é…¬) ä½œç‚º Y """
        self.data = self.data.sort_values([self.config['stock_id'],
                                           self.config['date']])
        self.data['future_price'] = self.data.groupby(self.config['stock_id'])[self.config['price']].shift(5)
        self.data.loc[:, 'weekly_return'] = (self.data[self.config['price']] - self.data['future_price']) / self.data['future_price']
        self.data.loc[:, 'weekly_return_c'] = (self.data['weekly_return'] > 0).astype(int)
        self.data = self.data.copy()

        self.data['prev_price'] = self.data.groupby(self.config['stock_id'])[self.config['price']].shift(5)
        self.data.loc[:, 'prev_weekly_return'] = (self.data[self.config['price']] - self.data['prev_price']) / self.data['prev_price']

        self.data = self.data.copy()

        return self.data
    
    def reduce_column(self):

        """ æ•´ç†ä¸€äº›ç›¸ä¼¼ data, æ¸›å°‘è®Šæ•¸ """

        self.data = self.data.copy()
        self.data['ä¸‰å¤§æ³•äººè²·è³£åƒ¹å·®'] = (self.data['å¤–è³‡è³£å‡åƒ¹'] - self.data['å¤–è³‡è²·å‡åƒ¹']) + \
                                (self.data['æŠ•ä¿¡è³£å‡åƒ¹'] - self.data['æŠ•ä¿¡è²·å‡åƒ¹']) + \
                                (self.data['è‡ªç‡Ÿå•†è³£å‡åƒ¹'] - self.data['è‡ªç‡Ÿå•†è²·å‡åƒ¹'])
        
        self.data['ä¸‰å¤§æ³•äººè²·è³£è¶…é‡‘é¡'] = self.data['å¤–è³‡è²·è³£è¶…é‡‘é¡(åƒ)'] + \
                                        self.data['æŠ•ä¿¡è²·è³£è¶…é‡‘é¡(åƒ)'] + \
                                        self.data['è‡ªç‡Ÿå•†è²·è³£è¶…é‡‘é¡(åƒ)']


    def process_data(self):

        """ åªå–æœ€æ–°ä¸€æœŸçš„åŸºæœ¬é¢æ•¸æ“š """
        fundamental_cols = self.config['no_rolling']
        self.data[fundamental_cols] = self.data.groupby(self.config['stock_id'])[fundamental_cols].ffill()
        return self.data

    def process_rolling_data(self):

        """ å–éå»5å¤©çš„æ³¢å‹•å¹³å‡ """
        volatility = self.config['rolling']
        for col in volatility:
            self.data[col] = self.data.groupby(self.config['stock_id'])[col].rolling(window=5, min_periods=1).mean().reset_index(0, drop=True)
        self.data = self.data.copy()
        return self.data

    def add_industry_variable(self):
        """ åŠ å…¥è¡Œæ¥­è®Šæ•¸ """
        self.data['industry'] = self.data[self.config['stock_name']].map(self.industry_dict)

        # æŠŠè¡Œæ¥­è½‰æ›æˆ one-hot ç·¨ç¢¼
        industry_dummies = pd.get_dummies(self.data['industry'], prefix='industry')
        self.data = pd.concat([self.data, industry_dummies], axis=1)

        # ç§»é™¤åŸå§‹çš„æ–‡å­—å‹è¡Œæ¥­è®Šæ•¸
        self.data.drop(columns=['industry'], inplace=True)
        self.data = self.data.copy()

        return self.data
    
    def filter_selected_columns(self):
        """ åªä¿ç•™ `config` ä¸­çš„æ¬„ä½ + è¡Œæ¥­è®Šæ•¸ """
        selected_cols = (
            [self.config['date'], self.config['stock_id'], self.config['stock_name'], 'weekly_return', 'weekly_return_c', 'prev_weekly_return'] +  # ä¸»è¦æ¨™è­˜æ¬„ä½ & Y
            self.config['no_rolling'] +
            self.config['rolling']
        )
        
        # åŠ å…¥è¡Œæ¥­è®Šæ•¸ï¼ˆæ‰€æœ‰ industry_ é–‹é ­çš„è®Šæ•¸ï¼‰
        industry_cols = [col for col in self.data.columns if col.startswith('industry_')]
        selected_cols += industry_cols

        # åªä¿ç•™ `selected_cols` ä¸­æœ‰çš„æ¬„ä½ï¼ˆé¿å…æ‰¾ä¸åˆ°æŸäº›æ¬„ä½ï¼‰
        self.data = self.data[selected_cols]

        return self.data
    
    def generate_daily_simple_data(self):
        """ ç”Ÿæˆç°¡åŒ–ç‰ˆæœ¬çš„ daily dataï¼ŒåªåŒ…å« `date`, `stock_id`, `stock_name`, `æ”¶ç›¤åƒ¹` """
        simple_data = self.data[[self.config['date'], self.config['stock_id'], 'stock_name', self.config['price']]].copy()
        return simple_data

    def merge_all_data(self):

        """ æœ€çµ‚è™•ç†æ•¸æ“šï¼Œåªä¿ç•™æ¯é€±äº”çš„æ•¸æ“š """
        self.data['day_of_week'] = pd.to_datetime(self.data[self.config['date']]).dt.weekday
        self.data = self.data[self.data['day_of_week'] == 0]  # åªä¿ç•™æ¯é€±ä¸€
        self.data.drop(columns=['day_of_week'], inplace=True)
        self.data.dropna(inplace=True)  # ç¢ºä¿æ²’æœ‰ç¼ºå¤±å€¼
        return self.data

    def process_all(self):

        """ ä¸€éµè™•ç†æ‰€æœ‰æ•¸æ“š """

        self.remove_incomplete_days()
        self.convert_to_numeric()

        simple_data = self.generate_daily_simple_data()  # ç°¡åŒ–ç‰ˆ

        self.reduce_column()
        self.calculate_weekly_return()
        self.process_data()
        self.process_rolling_data()

        self.add_industry_variable()
        self.filter_selected_columns()

        full_data = self.merge_all_data()

        return full_data, simple_data


class RollingWindowModel:
    def __init__(self, full_data, simple_data, model_name, rolling_days=60):
        """
        åˆå§‹åŒ–æ»¾å‹•çª—å£æ¨¡å‹
        :param full_data: åŒ…å«å®Œæ•´ç‰¹å¾µèˆ‡æ¨™ç±¤çš„æ•¸æ“š
        :param simple_data: ç°¡åŒ–ç‰ˆæ•¸æ“šï¼ˆåŒ…å« date, stock_id, stock_name, æ”¶ç›¤åƒ¹ï¼‰
        :param model_name: æ¨¡å‹åç¨±ï¼ˆå¦‚ 'LinearRegression', 'XGBoost', 'RandomForest', 'Lasso', 'Ridge', 'logistic - L1'ï¼‰
        :param rolling_days: æ»¾å‹•çª—å£é€±æ•¸
        """
        self.full_data = full_data
        self.simple_data = simple_data
        self.model_name = model_name
        self.rolling_days = rolling_days
        self.model = self._initialize_model(model_name)
        self.predictions = None
        self.mse = None

    def _initialize_model(self, model_name):
        """ æ ¹æ“šåç¨±å‰µå»ºå°æ‡‰çš„æ¨¡å‹ """
        if model_name == "LinearRegression":
            return LinearRegression()
        elif model_name == "Lasso":
            return Lasso(alpha=0.01, max_iter=5000, tol=1e-4)
        elif model_name == "Ridge":
            return Ridge(alpha=1.0)
        elif model_name == "ElasticNet":
            return ElasticNetCV(l1_ratio=np.linspace(0.1, 1, 10), alphas=np.logspace(-4, 2, 100), cv=5)
        elif model_name == "RandomForest":
            return RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
        elif model_name == "RandomForestClassifier":
            return RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
        elif model_name == "XGBoost":
            return xgb.XGBRegressor(objective="reg:squarederror", n_estimators=100, learning_rate=0.1)
        elif model_name == "XGBoostClassifier":
            return xgb.XGBClassifier(objective="binary:logistic", n_estimators=100, learning_rate=0.1)
        elif model_name == 'logistic - L1':
            return LogisticRegression(penalty='l1', solver='liblinear', C=0.1, max_iter=5000)
        else:
            raise ValueError(f"âŒ æœªçŸ¥çš„æ¨¡å‹åç¨±: {model_name}")

    @staticmethod
    def apply_pca(X_train, X_test, n_components=10):
        """
        ä½¿ç”¨ PCA é™ç¶­ï¼Œæ‰‹å‹•è¨­ç½® n_componentsï¼Œç¢ºä¿ä¸æœƒé™ç¶­éåº¦
        :param X_train: è¨“ç·´æ•¸æ“š
        :param X_test: æ¸¬è©¦æ•¸æ“š
        :param n_components: ä¿ç•™çš„ä¸»æˆåˆ†æ•¸é‡ï¼Œé è¨­ 10
        :return: é™ç¶­å¾Œçš„ X_train, X_test, pca_model
        """
        pca = PCA(n_components=n_components)  # è¨­å®šé™ç¶­ç‚º 10
        X_train_pca = pca.fit_transform(X_train)
        X_test_pca = pca.transform(X_test)

        print(f"ğŸ”¹ PCA é™ç¶­å¾Œç‰¹å¾µæ•¸: {X_train_pca.shape[1]} (åŸç‰¹å¾µæ•¸: {X_train.shape[1]})")
        
        return X_train_pca, X_test_pca, pca

    
    def model_input(self):

        '''æ•´ç†æ¨¡å‹è¼¸å…¥'''

        self.full_data['date'] = pd.to_datetime(self.full_data['date'])
        self.simple_data['date'] = pd.to_datetime(self.simple_data['date'])

        # é¸æ“‡ç‰¹å¾µåˆ—ï¼Œæ’é™¤éæ•¸å€¼å‹è®Šæ•¸
        all_feature_cols = [col for col in self.full_data.columns if col not in ['date', 'stock_id', 'stock_name', 'weekly_return', 'weekly_return_c']]
        sorted_data = self.full_data.sort_values(['date', 'stock_id']).reset_index(drop=True)

        unique_dates = sorted_data['date'].unique()
        self.start_date = unique_dates[self.rolling_days]

        return all_feature_cols, sorted_data, unique_dates
    
    def process_predictions(self, predictions, mse_list):
        '''è™•ç†é æ¸¬çµæœ'''
        final_predictions = pd.concat(predictions).reset_index(drop=True)
        avg_mse = np.mean(mse_list)  # è¨ˆç®—å¹³å‡ MSE æˆ–åˆ†é¡æº–ç¢ºç‡

        # åˆä½µç°¡åŒ– daily data
        final_predictions = pd.merge(self.simple_data, final_predictions, on=['date', 'stock_id', 'stock_name'], how='outer', suffixes=['', '_1'])

        final_predictions.sort_values(['stock_id', 'date'], inplace=True)
        final_predictions['rank'] = final_predictions.groupby('stock_id')['rank'].bfill(limit=5)
        final_predictions = final_predictions.dropna(subset=['rank'])  # ç§»é™¤ rank ç‚º NaN çš„è¡Œ

        # ç¢ºä¿åªä¿ç•™ `start_date` ä¹‹å¾Œçš„æ•¸æ“š
        final_predictions = final_predictions[final_predictions['date'] >= self.start_date].copy()

        # å„²å­˜é æ¸¬çµæœ
        self.predictions = final_predictions
        self.mse = avg_mse

        return final_predictions, avg_mse

    def rolling_window_prediction(self):
        """ ä½¿ç”¨ 60 é€±æ»¾å‹•çª—å£è¨“ç·´æ¨¡å‹ï¼Œå‰ 100 é€±ç¯©é¸è®Šæ•¸ï¼Œå¾ŒçºŒåƒ…ä¿ç•™ç©©å®šè®Šæ•¸ """

        all_feature_cols, sorted_data, unique_dates = self.model_input()

        predictions = []
        mse_list = []

        # è¨˜éŒ„å‰ 100 é€±çš„è®Šæ•¸é¸æ“‡æ¬¡æ•¸
        feature_selection_count = defaultdict(int)

        # æ»¾å‹•çª—å£
        for i in range(self.rolling_days, len(unique_dates)):
            train_dates = unique_dates[i - self.rolling_days:i]
            test_date = unique_dates[i]  # ç›®æ¨™é æ¸¬é€±

            # åˆ‡åˆ†è¨“ç·´é›† & æ¸¬è©¦é›†
            train_data = sorted_data[sorted_data['date'].isin(train_dates)]
            test_data = sorted_data[sorted_data['date'] == test_date]

            # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ†é¡æ¨¡å‹
            is_classification = self.model_name in ['logistic - L1', 'RandomForestClassifier', 'XGBoostClassifier']

            # é¸æ“‡ç›®æ¨™è®Šæ•¸
            target_col = 'weekly_return_c' if is_classification else 'weekly_return'

            # **è®Šæ•¸ç¯©é¸é‚è¼¯**
            if i < 100 + self.rolling_days:
                feature_cols = all_feature_cols  # å‰ 100 é€±ä½¿ç”¨æ‰€æœ‰è®Šæ•¸
            else:
                # åªä¿ç•™å‡ºç¾è¶…é 50%ï¼ˆè‡³å°‘ 50 æ¬¡ï¼‰çš„è®Šæ•¸
                feature_cols = [col for col, count in feature_selection_count.items() if count >= 50]
                if not feature_cols:
                    feature_cols = all_feature_cols  # ç¢ºä¿è‡³å°‘æœ‰è®Šæ•¸å¯ç”¨

            # åˆ†å‰²ç‰¹å¾µèˆ‡æ¨™ç±¤
            X_train, y_train = train_data[feature_cols], train_data[target_col]
            X_test, y_test = test_data[feature_cols], test_data[target_col]

            # è¨“ç·´æ¨¡å‹
            self.model.fit(X_train, y_train)

            # **å‰ 100 é€±è¨˜éŒ„è®Šæ•¸é¸æ“‡æƒ…æ³**
            if i < 100 + self.rolling_days:
                if hasattr(self.model, "coef_"):  # é©ç”¨æ–¼ Lassoã€Ridgeã€ElasticNet
                    selected_features = [feature_cols[j] for j in range(len(feature_cols)) if abs(self.model.coef_[j]) > 1e-6]
                    selected_features_weights = [self.model.coef_[j] for j in range(len(feature_cols)) if abs(self.model.coef_[j]) > 1e-6]
                    print(selected_features, selected_features_weights)
                elif hasattr(self.model, "feature_importances_"):  # é©ç”¨æ–¼éš¨æ©Ÿæ£®æ—ã€XGBoost
                    selected_features = [feature_cols[j] for j in range(len(feature_cols)) if self.model.feature_importances_[j] > 0]
                else:
                    selected_features = feature_cols  # è‹¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾µé¸æ“‡ï¼Œå‰‡ä½¿ç”¨å…¨éƒ¨ç‰¹å¾µ
                
                for feature in selected_features:
                    feature_selection_count[feature] += 1

            self.feature = feature_selection_count

            # é æ¸¬ä¸¦è¨ˆç®—è©•ä¼°æŒ‡æ¨™
            if is_classification:
                y_pred_proba = self.model.predict_proba(X_test)[:, 1]  # å–æ­£é¡çš„æ¦‚ç‡
                y_pred_class = self.model.predict(X_test)  # å–é æ¸¬é¡åˆ¥
                accuracy = accuracy_score(y_test, y_pred_class)  # è¨ˆç®—æº–ç¢ºç‡
                mse_list.append(accuracy)  # è¨˜éŒ„åˆ†é¡æº–ç¢ºç‡

                # å„²å­˜é æ¸¬çµæœ
                test_data = test_data.copy()
                test_data['pred_class'] = y_pred_class
                test_data['pred_proba'] = y_pred_proba
                test_data['rank'] = test_data['pred_proba'].rank(ascending=False, method='first')  # ä¾ç…§æ¦‚ç‡æ’åº
            else:
                y_pred = self.model.predict(X_test)
                mse = mean_squared_error(y_test, y_pred)
                mse_list.append(mse)

                # å„²å­˜é æ¸¬çµæœ
                test_data = test_data.copy()
                test_data['pred_return'] = y_pred
                test_data['rank'] = test_data['pred_return'].rank(ascending=False, method='first')  # ä¾ç…§å›æ­¸å€¼æ’åº

            predictions.append(test_data)

        # æ•´ç†æœ€çµ‚çµæœ
        final_predictions, avg_mse = self.process_predictions(predictions,
                                                              mse_list)

        # **è¿”å›é¸å‡ºçš„ç‰¹å¾µ**
        final_selected_features = [col for col, count in feature_selection_count.items() if count >= 50]
        
        return final_predictions, avg_mse, final_selected_features
    
    def rolling_pca_prediction(self):
        """ ä½¿ç”¨ PCA é™ç¶­ + ç°¡å–®ç·šæ€§å›æ­¸ é€²è¡Œæ»¾å‹•çª—å£é æ¸¬ """
        all_feature_cols, sorted_data, unique_dates = self.model_input()

        predictions = []
        mse_list = []

        # **ä½¿ç”¨ç°¡å–®ç·šæ€§å›æ­¸**
        base_model = self.model

        # æ»¾å‹•çª—å£
        for i in range(self.rolling_days, len(unique_dates)):
            train_dates = unique_dates[i - self.rolling_days:i]
            test_date = unique_dates[i]  # ç›®æ¨™é æ¸¬é€±

            # åˆ‡åˆ†è¨“ç·´é›† & æ¸¬è©¦é›†
            train_data = sorted_data[sorted_data['date'].isin(train_dates)]
            test_data = sorted_data[sorted_data['date'] == test_date]

            # é¸æ“‡ç›®æ¨™è®Šæ•¸
            target_col = 'weekly_return'

            # åˆ†å‰²ç‰¹å¾µèˆ‡æ¨™ç±¤
            X_train, y_train = train_data[all_feature_cols], train_data[target_col]
            X_test, y_test = test_data[all_feature_cols], test_data[target_col]

            # **é€²è¡Œ PCA é™ç¶­**
            X_train_pca, X_test_pca, pca_model = self.apply_pca(X_train, X_test, n_components=10)

            # è¨“ç·´ç°¡å–®å›æ­¸
            base_model.fit(X_train_pca, y_train)

            # **é æ¸¬ä¸¦è¨ˆç®— MSE**
            y_pred = base_model.predict(X_test_pca)
            mse = mean_squared_error(y_test, y_pred)
            mse_list.append(mse)

            # å„²å­˜é æ¸¬çµæœ
            test_data = test_data.copy()
            test_data['pred_return'] = y_pred
            test_data['rank'] = test_data['pred_return'].rank(ascending=False, method='first')

            predictions.append(test_data)

        # æ•´ç†æœ€çµ‚çµæœ
        final_predictions, avg_mse = self.process_predictions(predictions,
                                                              mse_list)
        # **å›å‚³ PCA ä¿ç•™çš„ä¸»æˆåˆ†æ•¸é‡**
        n_pca_features = X_train_pca.shape[1]

        return final_predictions, avg_mse, n_pca_features

    def fit_predict(self):

        return self.rolling_window_prediction()

    def run_backtest(self, strategy_module, column="rank", method=1, inventory_df=None):
        """
        åŸ·è¡Œå›æ¸¬
        :param strategy_module: å›æ¸¬ç­–ç•¥æ¨¡çµ„ï¼ˆå¦‚ MyStrategyï¼‰
        :param column: å›æ¸¬ä½¿ç”¨çš„æ’åºåˆ—
        :param ton: æ˜¯å¦è¦è¨ˆç®—äº¤æ˜“é‡
        """

        if self.predictions is None:
            print("âŒ è«‹å…ˆåŸ·è¡Œ `fit_predict()` ä¾†ç²å–é æ¸¬çµæœ")
            return
        
        # é¡¯ç¤º MSE
        print(f"æ¨¡å‹: {self.model.__class__.__name__}, å¹³å‡ MSE: {self.mse:.6f}, ç•°å¸¸é€±æ•¸: {(self.predictions.groupby('date')['rank'].nunique() != 50).sum()}")

        # é‡æ–°åŠ è¼‰ç­–ç•¥æ¨¡çµ„ï¼ˆé˜²æ­¢ Notebook æ²’æœ‰æ›´æ–°ï¼‰
        importlib.reload(strategy_module)

        print(f'Running backtest for column: {column} (sell strategy)')
        # é€²è¡Œå›æ¸¬
        if method == 1:
            strategy = strategy_module.Strategy0050(test_column=column, bos='sell', lookback_period=1)
        elif method == 2:
            strategy = strategy_module.weighted(test_column=column, bos='sell', lookback_period=1)
        elif method == 3:
            strategy = strategy_module.StrategyWithTracking(test_column=column, bos='sell', lookback_period=1)
        elif method == 4:
            strategy = strategy_module.Strategy0050WithIndicators(test_column=column, bos='sell', lookback_period=1)
        
        strategy.backtest(self.predictions)

        # é¡¯ç¤ºå›æ¸¬çµæœ
        res = strategy.calculate_performance_metrics()
        print(res)
        strategy.plot_pnl()
        self.lasso_weight = strategy.get_final_day_weights(self.predictions)

        if inventory_df is not None:
            self.trade_count = strategy.generate_trade_dataframe(inventory_df, self.predictions)

    def reg_result(self, check):
        
        check['np1'] = (check['weekly_return'] > 0 )
        check['np2'] = (check['pred_return'] > 0 )
        check['diff'] = (check['np1'] != check['np2'])
        print(f'overall winrate:{1 - check['diff'].mean()}')
        check_plot = check.groupby('date')
        check_plot['diff'].mean().plot()

        loss = []

        for i, j in check_plot:
            diff = j['weekly_return'] - j['pred_return']
            k = (j['diff']).astype(int) * diff.abs()
            loss.append(k)

        loss = np.array(loss)
        print(f'mean loss:{loss.mean()}')


class TuningWindowModel(RollingWindowModel):
    def __init__(self, full_data, simple_data, model_name, rolling_days=60, reuse_model_n_times=1):
        """
        :param reuse_model_n_times: è¨­å®šæ¯å€‹æ¨¡å‹é‡è¤‡ä½¿ç”¨çš„æ¬¡æ•¸ï¼Œé»˜èªç‚º 1
        """
        super().__init__(full_data, simple_data, model_name, rolling_days)
        self.reuse_model_n_times = reuse_model_n_times  # æ–°å¢åƒæ•¸
    
    def rolling_window_prediction(self):
        all_feature_cols, sorted_data, unique_dates = self.model_input()
        predictions = []
        mse_list = []
        
        i = self.rolling_days
        while i < len(unique_dates):
            train_dates = unique_dates[i - self.rolling_days:i]
            test_dates = unique_dates[i:i + self.reuse_model_n_times]  # é€™æ¬¡è¨“ç·´å¾Œæœƒé æ¸¬çš„æ—¥æœŸç¯„åœ
            
            train_data = sorted_data[sorted_data['date'].isin(train_dates)]
            test_data = sorted_data[sorted_data['date'].isin(test_dates)]
            
            target_col = 'weekly_return'
            
            X_train, y_train = train_data[all_feature_cols], train_data[target_col]
            X_test, y_test = test_data[all_feature_cols], test_data[target_col]
            
            self.model.fit(X_train, y_train)
            
            if not X_test.empty:
                y_pred = self.model.predict(X_test)
                test_data = test_data.copy()
                test_data['pred_return'] = y_pred
                test_data['rank'] = test_data['pred_return'].rank(ascending=False, method='first')
                predictions.append(test_data)
                
                mse = mean_squared_error(y_test, y_pred) if not y_test.isnull().all() else None
                if mse is not None:
                    mse_list.append(mse)
            
            i += self.reuse_model_n_times  # æ¯ reuse_model_n_times é€±é‡æ–°è¨“ç·´ä¸€æ¬¡
        
        return self.process_predictions(predictions, mse_list)
    
    def process_predictions(self, predictions, mse_list):
        '''è™•ç†é æ¸¬çµæœ'''
        final_predictions = pd.concat(predictions).reset_index(drop=True) if predictions else pd.DataFrame()
        avg_mse = np.mean(mse_list) if mse_list else None  # è¨ˆç®—å¹³å‡ MSE
        
        if not final_predictions.empty:
            final_predictions = pd.merge(self.simple_data, final_predictions, on=['date', 'stock_id', 'stock_name'], how='outer', suffixes=['', '_1'])
            final_predictions.sort_values(['stock_id', 'date'], inplace=True)
            final_predictions['rank'] = final_predictions.groupby('stock_id')['rank'].bfill(limit=5)
            final_predictions = final_predictions.dropna(subset=['rank'])
            final_predictions = final_predictions[final_predictions['date'] >= self.full_data['date'].min()].copy()
        
        return final_predictions, avg_mse
    
    def fit_predict(self):
        '''ç¢ºä¿ fit_predict æ–¹æ³•å­˜å„²é æ¸¬çµæœä»¥ä¾›å¾ŒçºŒä½¿ç”¨'''
        self.predictions, self.mse = self.rolling_window_prediction()
        return self.predictions, self.mse

